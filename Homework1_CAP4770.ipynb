{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NickYoungren/GraphProject/blob/main/Homework1_CAP4770.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "-MAxnJRz5sO5",
        "outputId": "da102109-0996-4082-9154-1b4214671d01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-209c7329-2e33-441f-a035-a9ee53f5cf5a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-209c7329-2e33-441f-a035-a9ee53f5cf5a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving smalltrain.csv to smalltrain.csv\n",
            "Saving test.csv to test.csv\n",
            "Saving train.csv to train.csv\n",
            "   near infra red   red  green  blue  class\n",
            "0              123  132    115   133      0\n",
            "1              152  150    119   187      1\n",
            "2              169  166    143   192      1\n",
            "3               55   49     43    97      0\n",
            "4              141  135    117   181      1\n",
            "   near infra red   red  green  blue  class\n",
            "0              137  140    129   150      0\n",
            "1              169  162    140   193      1\n",
            "2              124  110     89   162      1\n",
            "3              105  104     99   153      1\n",
            "4              105  102     88   173      1\n"
          ]
        }
      ],
      "source": [
        "# Load libraries\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import BaggingClassifier # Bagging Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier # Random Forest Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.linear_model import LogisticRegression # Import Logistic Regression Classifier\n",
        "from sklearn.svm import SVC # Import SVM classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "\n",
        "#USED to import the CSV files into the program\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "#note: class 0 for dry land, class 1 for wetland\n",
        "col_names = ['near infra red ', 'red', 'green', 'blue', 'class'] \n",
        "features =  ['near infra red ', 'red', 'green', 'blue'] \n",
        "\n",
        "# load dataset\n",
        "train_dat = pd.read_csv(\"train.csv\", header=None, names=col_names)\n",
        "print(train_dat.head())\n",
        "\n",
        "test_dat = pd.read_csv(\"test.csv\", header=None, names=col_names)\n",
        "print(test_dat.head())\n",
        "\n",
        "# COMPLETE CODES BELOW, compute training features X_train, training labels Y_train\n",
        "X_train = train_dat.drop('class', axis='columns')\n",
        "Y_train = train_dat['class']\n",
        "\n",
        "# COMPLETE CODES BELOW, compute test features X_test, test labels Y_test\n",
        "X_test = test_dat.drop('class', axis='columns')\n",
        "Y_test = test_dat['class']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1: Evaluate the performance of decision tree\n",
        "Run the codes below to train a decision tree, and make predictions on test samples"
      ],
      "metadata": {
        "id": "Wzg2CKROnn05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Decision Tree classifer object\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "dt = dt.fit(X_train,Y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "Y_pred = dt.predict(X_test)"
      ],
      "metadata": {
        "id": "fOpRPF2Mn6nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the codes below to compute the \"Overall Accuracy\", as well as Precision, Recall, and F-score for the Wetland class (class 1)"
      ],
      "metadata": {
        "id": "T3XTkPN8n_dX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in codes to calculate the values below; You can add any codes, but don't change the variable names\n",
        "\n",
        "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "\n",
        "precision_wet = metrics.precision_score(Y_test, Y_pred)\n",
        "\n",
        "recall_wet = metrics.recall_score(Y_test, Y_pred)\n",
        "\n",
        "F_wet = metrics.f1_score(Y_test, Y_pred)\n",
        "\n",
        "print(accuracy)\n",
        "print(precision_wet)\n",
        "print(recall_wet)\n",
        "print(F_wet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KbEiRW2oDXh",
        "outputId": "2b69b688-3c29-4294-8222-d46f223e8b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.781\n",
            "0.737885462555066\n",
            "0.7701149425287356\n",
            "0.7536557930258717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=red>ANSWER THE QUESTION BELOW.</font> How do you think about the performance shown by different metrics above. Is accuracy a good metric to reflect classification performance? Why? You can discuss your answer as a string. And print it out. "
      ],
      "metadata": {
        "id": "tXj1g9NroH6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MY ANSWER IS xxxxx\n",
        "ans = '''\n",
        "Overall the measurements show that the performance level was not perfect, but still netted relatively good accuracy, precision, recall and F-measure. Accuracy can be a good metric, but it can be very misleading because the data might be imbalanced (the model might be getting the right answer by mistake). It's important to take into consideration precision/recall/F-score along with accuracy so that you can see if your model is truly accurate.\n",
        "'''\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTfJ5VO7oOJk",
        "outputId": "339712cf-94b4-4c51-c1cf-b5771bae605f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall the measurements show that the performance level was not perfect, but still netted relatively good accuracy, precision, recall and F-measure. Accuracy can be a good metric, but it can be very misleading because the data might be imbalanced (the model might be getting the right answer by mistake). It's important to take into consideration precision/recall/F-score along with accuracy so that you can see if your model is truly accurate.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Overfitting issues\n",
        "<font color=red>PLEASE COMPLETE THE CODES BELOW.</font> Please re-train the decision tree model with a smaller number of training samples. <font color=red>DO NOT change the tree model parameters (e.g., minimum leaf node size) from Part 1</font>"
      ],
      "metadata": {
        "id": "QlI3v_qVobnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-run the training and testing based on a smaller training set (smalltrain.csv).\n",
        "#note: class 0 for dry land, class 1 for wetland\n",
        "col_names = ['near infra red ', 'red', 'green', 'blue', 'class'] \n",
        "features =  ['near infra red ', 'red', 'green', 'blue'] \n",
        "\n",
        "# load dataset\n",
        "train_dat = pd.read_csv(\"smalltrain.csv\", header=None, names=col_names)\n",
        "print(train_dat.head())\n",
        "\n",
        "test_dat = pd.read_csv(\"test.csv\", header=None, names=col_names)\n",
        "print(test_dat.head())\n",
        "\n",
        "# COMPLETE CODES BELOW, compute training features X_train, training labels Y_train\n",
        "X_train = train_dat.drop('class', axis='columns')\n",
        "Y_train = train_dat['class']\n",
        "\n",
        "# COMPLETE CODES BELOW, compute test features X_test, test labels Y_test\n",
        "X_test = test_dat.drop('class', axis='columns')\n",
        "Y_test = test_dat['class']\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "dt = dt.fit(X_train,Y_train)\n",
        "\n",
        "# Re-evaluate the trained model on test data, print out accuracy, precision, recall, F-score\n",
        "Y_pred = dt.predict(X_train)\n",
        "\n",
        "accuracy = metrics.accuracy_score(Y_train, Y_pred)\n",
        "precision_wet = metrics.precision_score(Y_train, Y_pred)\n",
        "recall_wet = metrics.recall_score(Y_train, Y_pred)\n",
        "F_wet = metrics.f1_score(Y_train, Y_pred)\n",
        "\n",
        "print('Metrics of Model on Training Data')\n",
        "print(accuracy)\n",
        "print(precision_wet)\n",
        "print(recall_wet)\n",
        "print(F_wet)\n",
        "\n",
        "Y_pred = dt.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "precision_wet = metrics.precision_score(Y_test, Y_pred)\n",
        "recall_wet = metrics.recall_score(Y_test, Y_pred)\n",
        "F_wet = metrics.f1_score(Y_test, Y_pred)\n",
        "\n",
        "print('Metrics of Model on Test Data')\n",
        "print(accuracy)\n",
        "print(precision_wet)\n",
        "print(recall_wet)\n",
        "print(F_wet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ0HkWlXogHP",
        "outputId": "1b057e88-d47f-4240-fbf8-ae7a74a72d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   near infra red   red  green  blue  class\n",
            "0              143  150    145   156      0\n",
            "1              151  143    120   183      1\n",
            "2              100   98     86   156      0\n",
            "3              140  137    119   182      0\n",
            "4              147  147    138   160      0\n",
            "   near infra red   red  green  blue  class\n",
            "0              137  140    129   150      0\n",
            "1              169  162    140   193      1\n",
            "2              124  110     89   162      1\n",
            "3              105  104     99   153      1\n",
            "4              105  102     88   173      1\n",
            "Metrics of Model on Training Data\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "Metrics of Model on Test Data\n",
            "0.704\n",
            "0.6635294117647059\n",
            "0.6482758620689655\n",
            "0.6558139534883721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=red>ANSWER THE QUESTION BELOW.</font> What do you observe when the number of training samples decrese? Is this overfitting or underfitting?"
      ],
      "metadata": {
        "id": "73Yjz0AQooPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MY Answer: xxxxxxxxxxx\n",
        "ans = '''\n",
        "We observed that as the number of training samples decrease, the performance of the model on the test set decreases compared to the performance on the training set. Specifically, the accuracy, precision, recall, and F-score of the model on the test set are lower than those on the training set. This leads us to believe that the model may be overfitting to the training data, as it has learned to fit the noise in the training data rather than the underlying pattern that generalizes to new data. Therefore, the decrease in performance is an indication of overfitting.\n",
        "'''\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "id": "u7ElgRwCorLt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd42d35c-33d6-4297-b6f6-32c251952b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "We observed that as the number of training samples decrease, the performance of the model on the test set decreases compared to the performance on the training set. Specifically, the accuracy, precision, recall, and F-score of the model on the test set are lower than those on the training set. This leads us to believe that the model may be overfitting to the training data, as it has learned to fit the noise in the training data rather than the underlying pattern that generalizes to new data. Therefore, the decrease in performance is an indication of overfitting.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now do another experiment to mitigate the effect of overfitting by decreasing the model complexity. We keep using the small training data (smalltrain.csv) that leads to overfitting. We decrease model complexity by having a larger minimum leaf node size (\"min_sample_split=30\")."
      ],
      "metadata": {
        "id": "5X6r2skkotcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_names = ['near infra red ', 'red', 'green', 'blue', 'class'] \n",
        "features =  ['near infra red ', 'red', 'green', 'blue'] \n",
        "\n",
        "# load dataset\n",
        "train_dat = pd.read_csv(\"smalltrain.csv\", header=None, names=col_names)\n",
        "print(train_dat.head())\n",
        "\n",
        "test_dat = pd.read_csv(\"test.csv\", header=None, names=col_names)\n",
        "print(test_dat.head())\n",
        "\n",
        "# COMPLETE CODES BELOW, compute training features X_train, training labels Y_train\n",
        "X_train = train_dat.drop('class', axis='columns')\n",
        "Y_train = train_dat['class']\n",
        "\n",
        "# COMPLETE CODES BELOW, compute test features X_test, test labels Y_test\n",
        "X_test = test_dat.drop('class', axis='columns')\n",
        "Y_test = test_dat['class']\n",
        "\n",
        "# Create Decision Tree classifer object\n",
        "dt_simple = DecisionTreeClassifier(min_samples_split=30) ### Make model much simplier by requiring 30 samples to split\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "dt_simple = dt_simple.fit(X_train, Y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "Y_pred = dt_simple.predict(X_test)\n",
        "\n",
        "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "precision_wet = metrics.precision_score(Y_test, Y_pred)\n",
        "recall_wet = metrics.recall_score(Y_test, Y_pred)\n",
        "F_wet = metrics.f1_score(Y_test, Y_pred)\n",
        "\n",
        "print('Metrics of Model on Test Data')\n",
        "print(accuracy)\n",
        "print(precision_wet)\n",
        "print(recall_wet)\n",
        "print(F_wet)"
      ],
      "metadata": {
        "id": "hjDat9tvozkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce109616-ed6e-4b04-95b4-c9526ded78de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   near infra red   red  green  blue  class\n",
            "0              143  150    145   156      0\n",
            "1              151  143    120   183      1\n",
            "2              100   98     86   156      0\n",
            "3              140  137    119   182      0\n",
            "4              147  147    138   160      0\n",
            "   near infra red   red  green  blue  class\n",
            "0              137  140    129   150      0\n",
            "1              169  162    140   193      1\n",
            "2              124  110     89   162      1\n",
            "3              105  104     99   153      1\n",
            "4              105  102     88   173      1\n",
            "Metrics of Model on Test Data\n",
            "0.757\n",
            "0.6882352941176471\n",
            "0.8068965517241379\n",
            "0.742857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=red>ANSWER THE QUESTION BELOW.</font> Compare the results above with the results from the beginning of Part 2 (smalltrain.csv with the original decision tree without decreasing model complexity), what did you observe? "
      ],
      "metadata": {
        "id": "lwX7Gygno3bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MY ANSWER IS xxxxx\n",
        "ans = '''\n",
        "Comparing the results of Part 3 with the results of Part 2, we can see that the decision tree model in Part 3 performed better in terms of accuracy, precision, recall, and F1 score on the test data. This indicates that reducing the complexity of the model by limiting the depth of the decision tree and setting a minimum number of samples required to split a node helped to prevent overfitting and improved the model's generalization performance. Additionally, the accuracy and other metrics on the training data were lower in Part 3 compared to Part 2, which suggests that the model in Part 3 is less likely to overfit to the training data.\n",
        "'''\n",
        "print(ans)"
      ],
      "metadata": {
        "id": "RFYXKIefo6Jp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7785db-37be-4cc9-e52d-9ae60c9c48f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparing the results of Part 3 with the results of Part 2, we can see that the decision tree model in Part 3 performed better in terms of accuracy, precision, recall, and F1 score on the test data. This indicates that reducing the complexity of the model by limiting the depth of the decision tree and setting a minimum number of samples required to split a node helped to prevent overfitting and improved the model's generalization performance. Additionally, the accuracy and other metrics on the training data were lower in Part 3 compared to Part 2, which suggests that the model in Part 3 is less likely to overfit to the training data.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Compare different model on the same test data\n",
        "In this part, you will train other types of models and evaluate on the test data. You will compare their classification performance.\n",
        "\n",
        "<font color=red>PLEASE COMPLETE TEH CODES BELOW.</font> PLEASE USE THE SAME TRAINING AND TEST DATA as in Part 1."
      ],
      "metadata": {
        "id": "o2x_VcPDo8RZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "col_names = ['near infra red ', 'red', 'green', 'blue', 'class'] \n",
        "features =  ['near infra red ', 'red', 'green', 'blue'] \n",
        "\n",
        "# load dataset\n",
        "train_dat = pd.read_csv(\"train.csv\", header=None, names=col_names)\n",
        "print(train_dat.head())\n",
        "\n",
        "test_dat = pd.read_csv(\"test.csv\", header=None, names=col_names)\n",
        "print(test_dat.head())\n",
        "\n",
        "# COMPLETE CODES BELOW, compute training features X_train, training labels Y_train\n",
        "X_train = train_dat.drop('class', axis='columns')\n",
        "Y_train = train_dat['class']\n",
        "\n",
        "# COMPLETE CODES BELOW, compute test features X_test, test labels Y_test\n",
        "X_test = test_dat.drop('class', axis='columns')\n",
        "Y_test = test_dat['class']\n",
        "\n",
        "# train a logistic regression model; e.g., use the LogisticRegression model in Scikit-Learn.\n",
        "# using parameter \"solver='liblinear'\"\n",
        "lr = LogisticRegression(solver='liblinear')\n",
        "lr = lr.fit(X_train, Y_train)\n",
        "Y_pred = lr.predict(X_test)\n",
        "\n",
        "# evalute the logistic regression model on test data\n",
        "\n",
        "\n",
        "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "precision_wet = metrics.precision_score(Y_test, Y_pred)\n",
        "recall_wet = metrics.recall_score(Y_test, Y_pred)\n",
        "F_wet = metrics.f1_score(Y_test, Y_pred)\n",
        "\n",
        "print(accuracy)\n",
        "print(precision_wet)\n",
        "print(recall_wet)\n",
        "print(F_wet)"
      ],
      "metadata": {
        "id": "Y34jBYh9o-6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "428ec040-200f-4d84-d091-a4694b147dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   near infra red   red  green  blue  class\n",
            "0              123  132    115   133      0\n",
            "1              152  150    119   187      1\n",
            "2              169  166    143   192      1\n",
            "3               55   49     43    97      0\n",
            "4              141  135    117   181      1\n",
            "   near infra red   red  green  blue  class\n",
            "0              137  140    129   150      0\n",
            "1              169  162    140   193      1\n",
            "2              124  110     89   162      1\n",
            "3              105  104     99   153      1\n",
            "4              105  102     88   173      1\n",
            "0.757\n",
            "0.7307692307692307\n",
            "0.6988505747126437\n",
            "0.7144535840188013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train a Support Vector Machine (SVM) model, e.g., the SVC model in Scikit-Learn, choose parameters approprioately\n",
        "\n",
        "# Please find the SVC function in Scikit-Learn, use parameters \"gamma='scale', C=100\"\n",
        "clf = SVC(gamma='scale', C=100)\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "# evalute the Support Vector Machine (SVM) model on test data\n",
        "Y_pred = clf.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "precision_wet = metrics.precision_score(Y_test, Y_pred)\n",
        "recall_wet = metrics.recall_score(Y_test, Y_pred)\n",
        "F_wet = metrics.f1_score(Y_test, Y_pred)\n",
        "\n",
        "print(accuracy)\n",
        "print(precision_wet)\n",
        "print(recall_wet)\n",
        "print(F_wet)"
      ],
      "metadata": {
        "id": "8TwYtzRjpD0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5505fc5f-945c-443a-8608-d7c8c38d32d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.81\n",
            "0.7406679764243614\n",
            "0.8666666666666667\n",
            "0.798728813559322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=red>ANSWER THE QUESTION BELOW.</font> How do you compare the results from different models above with decision tree?"
      ],
      "metadata": {
        "id": "Ns4rhsPSpGyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ans = '''\n",
        "Comparing the results from different models with the decision tree, it appears that the SVM model performs the best in terms of overall accuracy and precision/recall scores. The logistic regression model also performs well but not as well as the SVM. The decision tree model, on the other hand, has lower accuracy and precision/recall scores compared to the other models. This suggests that using more complex models such as SVM or logistic regression may be more effective in accurately predicting the class labels of the test data compared to using a simple decision tree model. However, it's important to note that the choice of model depends on the specific requirements and constraints of the problem at hand.\n",
        "'''\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "id": "CORCQgb2pJDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a856ba-2b09-4299-891a-21e4ebbb7dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparing the results from different models with the decision tree, it appears that the SVM model performs the best in terms of overall accuracy and precision/recall scores. The logistic regression model also performs well but not as well as the SVM. The decision tree model, on the other hand, has lower accuracy and precision/recall scores compared to the other models. This suggests that using more complex models such as SVM or logistic regression may be more effective in accurately predicting the class labels of the test data compared to using a simple decision tree model. However, it's important to note that the choice of model depends on the specific requirements and constraints of the problem at hand.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Ensemble learning\n",
        "In this part, you will run several ensemble learning of decision trees, including bagging and random forest. For random forest, you can directly call it as a separate model from library.\n",
        "\n",
        "<font color=red>PLEASE COMPLETE CODES BELOW</font>. PLEASE USE THE ORIGINAL TRAINING AND TEST DATA in Part 1."
      ],
      "metadata": {
        "id": "Bar6JHv2pLto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#note: class 0 for dry land, class 1 for wetland\n",
        "col_names = ['near infra red ', 'red', 'green', 'blue', 'class'] \n",
        "features =  ['near infra red ', 'red', 'green', 'blue'] \n",
        "\n",
        "# load dataset\n",
        "train_dat = pd.read_csv(\"train.csv\", header=None, names=col_names)\n",
        "print(train_dat.head())\n",
        "\n",
        "test_dat = pd.read_csv(\"test.csv\", header=None, names=col_names)\n",
        "print(test_dat.head())\n",
        "\n",
        "# COMPLETE CODES BELOW, compute training features X_train, training labels Y_train\n",
        "X_train = train_dat.drop('class', axis='columns')\n",
        "Y_train = train_dat['class']\n",
        "\n",
        "# COMPLETE CODES BELOW, compute test features X_test, test labels Y_test\n",
        "X_test = test_dat.drop('class', axis='columns')\n",
        "Y_test = test_dat['class']\n",
        "\n",
        "# please train bagging of decision tree, using BaggingClassifier with default parameters\n",
        "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier())\n",
        "clf = clf.fit(X_train, Y_train)\n",
        "\n",
        "# please evaluate it on the test data\n",
        "Y_pred = clf.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "precision_wet = metrics.precision_score(Y_test, Y_pred)\n",
        "recall_wet = metrics.recall_score(Y_test, Y_pred)\n",
        "F_wet = metrics.f1_score(Y_test, Y_pred)\n",
        "\n",
        "print(accuracy)\n",
        "print(precision_wet)\n",
        "print(recall_wet)\n",
        "print(F_wet)"
      ],
      "metadata": {
        "id": "7QGE6FRtpPWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce48764-8f4d-4173-c68c-1cd5b09bb8e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   near infra red   red  green  blue  class\n",
            "0              123  132    115   133      0\n",
            "1              152  150    119   187      1\n",
            "2              169  166    143   192      1\n",
            "3               55   49     43    97      0\n",
            "4              141  135    117   181      1\n",
            "   near infra red   red  green  blue  class\n",
            "0              137  140    129   150      0\n",
            "1              169  162    140   193      1\n",
            "2              124  110     89   162      1\n",
            "3              105  104     99   153      1\n",
            "4              105  102     88   173      1\n",
            "0.803\n",
            "0.7833333333333333\n",
            "0.7563218390804598\n",
            "0.7695906432748538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# please train a random forest, using RandomForestClassifier function with paramters \"n_estimators=50\"\n",
        "clf = RandomForestClassifier(n_estimators=50)\n",
        "clf = clf.fit(X_train, Y_train)\n",
        "\n",
        "# please evaluate it on the test data\n",
        "Y_pred = clf.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(Y_test, Y_pred)\n",
        "precision_wet = metrics.precision_score(Y_test, Y_pred)\n",
        "recall_wet = metrics.recall_score(Y_test, Y_pred)\n",
        "F_wet = metrics.f1_score(Y_test, Y_pred)\n",
        "\n",
        "print(accuracy)\n",
        "print(precision_wet)\n",
        "print(recall_wet)\n",
        "print(F_wet)"
      ],
      "metadata": {
        "id": "KNXOnOglpYHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67faed3-0679-4cc4-ff16-2dbac251cdb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.812\n",
            "0.7738359201773836\n",
            "0.8022988505747126\n",
            "0.7878103837471783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLEASE ANSWER THE QUESTION BELOW. How do you compare different ensemble methods? Which one has the best performance?"
      ],
      "metadata": {
        "id": "ZeNeaMRNpacH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ans = '''\n",
        "The random forest model with 50 estimators has the best performance among the two ensemble methods. It has a higher accuracy and F1 score on the test data compared to the bagging of decision tree. However, it is important to note that the performance of the models may vary depending on the dataset and the specific parameters used. It is also possible that other ensemble methods, such as boosting or stacking, may perform better on this dataset.\n",
        "'''\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "id": "k2V7pWstpdnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d5174d8-9846-4916-8c77-5ec67a31bacf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The random forest model with 50 estimators has the best performance among the two ensemble methods. It has a higher accuracy and F1 score on the test data compared to the bagging of decision tree. However, it is important to note that the performance of the models may vary depending on the dataset and the specific parameters used. It is also possible that other ensemble methods, such as boosting or stacking, may perform better on this dataset.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5 (EXTRA CREDIT): Implement your own classifier (logistic regression)\n",
        "\n",
        "You should implement your logistic regression model: a training function and a test function. Save your source codes in 'myLR.py'. Put the python script in the same dirctory of this Jupyter Notebook. Load the scripts so that you can call your own training and prediction functions. Then evaluate the results on test data. Compare your results from the results from built-in logistic regression library in Part 4. Please use the same training data and test data as Part 1. Please make sure you print out the accuracy, confusion matrix, precision, recall, F-score. \n",
        "\n",
        "<b>Requirement</b>\n",
        "\n",
        "- Your codes should run through without bugs. Codes with bugs in Jupyter notebook running will NOT be graded. \n",
        "    \n",
        "- You CANNOT copy a same python codes from online for this question. It will be treated as cheating.\n",
        "\n"
      ],
      "metadata": {
        "id": "KjsMzAldpf7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "col_names = ['near infra red ', 'red', 'green', 'blue', 'class'] \n",
        "features =  ['near infra red ', 'red', 'green', 'blue'] \n",
        "\n",
        "# load dataset\n",
        "train_dat = pd.read_csv(\"train.csv\", header=None, names=col_names)\n",
        "print(train_dat.head())\n",
        "\n",
        "test_dat = pd.read_csv(\"test.csv\", header=None, names=col_names)\n",
        "print(test_dat.head())\n",
        "\n",
        "# COMPLETE CODES BELOW, compute training features X_train, training labels Y_train\n",
        "X_train = \n",
        "Y_train = \n",
        "\n",
        "# COMPLETE CODES BELOW, compute test features X_test, test labels Y_test\n",
        "X_test = \n",
        "Y_test = \n",
        "\n",
        "# Load your implemented codes myLR.py\n",
        "from myLR import MyLR\n",
        "\n",
        "# Call your own function to train a logistic regression model, as what we did in Part 1 with decision tree\n",
        "myLR = MyLR()\n",
        "myLR = myLR.fit(X_train, Y_train)\n",
        "\n",
        "# Call your own function to make prediction on test data, and evaluate those metrics, as what we did in Part 1 with deicsion tree\n",
        "Y_pred = \n",
        "print(Y_pred.head())\n",
        "print(Y_pred.shape)\n",
        "\n",
        "# evalute the logistic regression model on test data\n",
        "confusion_matrix = \n",
        "accuracy = \n",
        "precision_wet = \n",
        "recall_wet = \n",
        "F_wet = \n",
        "\n",
        "print(confusion_matrix)\n",
        "print(accuracy)\n",
        "print(precision_wet)\n",
        "print(recall_wet)\n",
        "print(F_wet)"
      ],
      "metadata": {
        "id": "e5quJXjRpjNJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "c765c42d-fb17-4d96-ab9e-2714457d9774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-1b2f25f676a8>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    X_train =\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}